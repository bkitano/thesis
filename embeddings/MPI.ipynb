{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to create the Mutual Pointwise Information (MPI) matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the batched pickle cooccurrence matrices\n",
    "\n",
    "cooccurPath = '/Users/bkitano/Desktop/Classes/spring_2019/thesis/embeddings/halfcentury/'\n",
    "\n",
    "import pickle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "with open('./IDToWord.p', 'rb') as fp:\n",
    "    IDToWord = pickle.load(fp)\n",
    "    \n",
    "with open('./WordToID.p', 'rb') as fp:\n",
    "    wordToID = pickle.load(fp)\n",
    "\n",
    "cooccurFiles = [f for f in listdir(cooccurPath) if isfile(join(cooccurPath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "for cFile in cooccurFiles:\n",
    "    with open(\"./halfcentury/\" + cFile, \"rb\") as fp:\n",
    "        batches.append(pickle.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "currently, matrices are X[word][coword] = 1,\n",
    "so X[word_a][word_b] != X[word_b][word_a], \n",
    "since if a word is not included in the window it won't show up;\n",
    "e.g. if the string is \"a b c d e f g\" and L = 3,\n",
    "(d, [a b c d e f g])\n",
    "but\n",
    "a won't get a pairing, since it doesn't have a left window; thus\n",
    "X[d,a] != X[a,d]\n",
    "\n",
    "this is really the approximate cooccurence, and it's really only \n",
    "inaccurate for the first and last 5 words in a document.\n",
    "'''\n",
    "meanBatches = [(b + b.T)/2.0 for b in batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "# X = meanBatches[0]\n",
    "f = 10000\n",
    "X = csr_matrix(np.random.randint(0,f, (f,f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = np.ones(len(wordToID))\n",
    "o = np.ones(f)\n",
    "S = X.dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bkitano/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "X.setdiag(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = np.sum(X.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.875932216644287\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from scipy.special import xlogy\n",
    "# now X is the thing we want, discretely. so we have to do the scaling.\n",
    "# want log (X[i,j] * trace(X) / X[i]X[j])\n",
    "# log(X[i,j]) - log(X[i]) - log(X[j]) + log(trace(X))\n",
    "# ETA for xlogy: 9578 seconds = 2h40m\n",
    "\n",
    "a = time.time()\n",
    "logXij = xlogy(np.sign(X.todense()), X.todense())\n",
    "print(time.time() - a)\n",
    "print(logXij.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0980331897735596\n"
     ]
    }
   ],
   "source": [
    "b = time.time()\n",
    "Xj = np.tile(S, [f, 1])\n",
    "logXj = xlogy(np.sign(Xj), Xj)\n",
    "print(time.time() - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017750263214111328\n"
     ]
    }
   ],
   "source": [
    "c = time.time()\n",
    "logXi = logXj.T\n",
    "print(time.time() - c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2689318656921387\n"
     ]
    }
   ],
   "source": [
    "d = time.time()\n",
    "trace = np.trace(X.todense())\n",
    "logTraceX = np.ones((f, f))*np.log(trace)\n",
    "print(time.time() - d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.707242965698242\n"
     ]
    }
   ],
   "source": [
    "e = time.time()\n",
    "PMI = logXij + logTraceX - logXi - logXj\n",
    "print(time.time() - e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPMI = np.multiply(PMI, np.greater(PMI, np.zeros((f,f))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./ppmi/slice{}.p'.format('test'), 'wb') as fp:\n",
    "    pickle.dump(PPMI, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
