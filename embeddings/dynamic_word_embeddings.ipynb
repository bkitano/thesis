{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's been cleaned, and so we need to write the sentences to a format that can be ingested by the Dynamic Word Embeddings training script.\n",
    "\n",
    "DWE takes as input PMI matrices for each time slice, after removing words that appear infrequently and stop words. We need to set a window size L to calculate window size, and in the Word2Vec paper, they suggest a window of 20 for small corpora.\n",
    "\n",
    "We'll have to make a vocabulary to wordID dictionary, and do this over all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32830"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate rare words\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "textPath = '/Users/bkitano/Desktop/Classes/Spring_2019/thesis/corpus/cleaned_txt/'\n",
    "\n",
    "onlyfiles = [f for f in listdir(textPath) if isfile(join(textPath, f))]\n",
    "\n",
    "len(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frequency distribution\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import re\n",
    "\n",
    "english_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1671-A53048.txt\n"
     ]
    }
   ],
   "source": [
    "# do it in batches\n",
    "freqDistsPath = '/Users/bkitano/Desktop/Classes/spring_2019/thesis/embeddings/freqDists/'\n",
    "\n",
    "batchSize = 100\n",
    "batches = [onlyfiles[i:i + batchSize] for i in range(0, len(onlyfiles), batchSize)]\n",
    "timeElapsed = 0\n",
    "\n",
    "lastTime = time.time()\n",
    "for batchIndex in range(1, len(batches)+1):\n",
    "    \n",
    "    batch = batches[batchIndex-1]\n",
    "\n",
    "    freq = Counter()\n",
    "    for i in range(len(batch)):\n",
    "        filename = batch[i]\n",
    "        \n",
    "        try:\n",
    "            with open( textPath + filename, 'r+') as f:\n",
    "                rawtext = f.read()\n",
    "                tokens = [t for t in nltk.word_tokenize(text) if t.isalpha() and t.lower() not in english_stopwords]\n",
    "                totalTokensCount += len(tokens)\n",
    "                freq += nltk.FreqDist(tokens)\n",
    "        except:\n",
    "            print(filename)\n",
    "    \n",
    "    with open(freqDistsPath + \"batch\"+ str(i) + \".csv\", \"a+\") as f:\n",
    "        for k,v in freq.most_common():\n",
    "            f.write( \"{}, {}\\n\".format(k,v) )\n",
    "\n",
    "    batchTime = time.time() - lastTime\n",
    "    timeElapsed += batchTime\n",
    "    ETA = time.time() + (timeElapsed/batchIndex) * (len(batches) - batchIndex)\n",
    "    ETAstring = \"{}:{}:{}\".format( int(ETA / 3600), int( (ETA % 3600) / 60 ), int(ETA % 60))\n",
    "\n",
    "    print(\"Batch {} of {} | Batch time: {} | ETA: {}\".format(batchIndex, len(batches), batchTime, ETAstring))\n",
    "    lastTime = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be fruitful to develop machine learning approaches to unsupervised learning of spelling variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now all of the freqDist have been saved as csv's, so we need to merge them into one large csv. We also need to remove all the docs that couldn't be parsed. oof i fucked that one up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDistPath = '/Users/bkitano/Desktop/Classes/Spring_2019/thesis/embeddings/freqDists/'\n",
    "\n",
    "freqDistFiles = [f for f in listdir(freqDistPath) if isfile(join(freqDistPath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "[('god', 3156851), ('one', 2268075), ('upon', 2256671), ('may', 2243437), ('shall', 2129379), ('us', 1831379), ('man', 1797155), ('would', 1713276), ('great', 1654792), ('men', 1574743)]\n"
     ]
    }
   ],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "totalFreqDist = Counter()\n",
    "\n",
    "for freqDistFile in freqDistFiles:\n",
    "    try:\n",
    "        with open(freqDistPath + freqDistFile) as f:\n",
    "            reader = DictReader(f, fieldnames=['word', 'count'])\n",
    "            freqDist = Counter({row['word']: int(row['count']) for row in reader})\n",
    "            totalFreqDist += freqDist\n",
    "    except:\n",
    "        print(freqDistFile)\n",
    "        \n",
    "print(totalFreqDist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(freqDistPath + \"totalFreqDist.csv\", \"a+\") as f:\n",
    "        for k,v in totalFreqDist.most_common():\n",
    "            f.write( \"{}, {}\\n\".format(k,v) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'totalFreqDist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c5f9a9e5c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalFreqDist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'totalFreqDist' is not defined"
     ]
    }
   ],
   "source": [
    "print(totalFreqDist.most_common(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
